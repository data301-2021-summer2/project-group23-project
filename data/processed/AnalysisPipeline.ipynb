{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "da0e1711-5cc7-4347-9519-85041ef08d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe7402a-299e-402f-a0fa-3c896a3f33b2",
   "metadata": {},
   "source": [
    "# **Analysis Pipleine - Group 23 - David Olson**\n",
    "---\n",
    "- (note: This pipeline will continue to be updated as I work on ALL 4 milestones.)\n",
    "---\n",
    "## **1. Load Data**\n",
    "### Steps taken:\n",
    "- Loaded data, there is a difference in date. SPY has values from 1993-2020, and TSLA has values from 2010-2020.\n",
    "- I will remove 1993-2010 from spy so the dates tracked are the same as TSLA's\n",
    "- There are initially 7 columns in each dataframe, I aim to get that to 7 columns total as a merged dataframe.\n",
    "- To do this, I will have to remove some columns that I think are least necessary.\n",
    "- add link for:\n",
    "    - milestone1.ipynb (these are the initial 2 dataframes.)\n",
    "---\n",
    "## **2. Clean Data** (Note: Steps 2,3, and 4 link together and there may be some cleaning/processing/wrangling steps in all 3 steps)\n",
    "### Steps taken:\n",
    "- I created a function with method-chaining called \"load_and_clean_tsla_spy\" that loads the dataframes, removes the \"High\", \"Low\", and \"Adj. Close\" columns, and renames the \"Open\", \"Close\", and \"Volume\" columns to \"open_spy\" or \"open_tsla\", \"close_spy\" or \"close_tsla\", and \"vol_spy\" or \"vol_tsla\" from both dataframes. It also converts the date column to datetime.\n",
    "---\n",
    "```\n",
    "def load_and_clean_tsla_spy(spy,tsla):\n",
    "    tsladf = (pd.read_csv(tsla, parse_dates=[\"Date\"])\n",
    "              .drop(columns=[\"High\",\"Low\",\"Adj Close\"])\n",
    "              .rename(columns={\"Open\":\"open_tsla\",\"Close\":\"close_tsla\",\"Volume\":\"vol_tsla\"})\n",
    "              .reset_index(drop=True))\n",
    "    spydf = (pd.read_csv(spy, parse_dates=[\"Date\"])\n",
    "             .drop(columns=[\"High\",\"Low\",\"Adj Close\"])\n",
    "             .rename(columns={\"Open\":\"open_spy\",\"Close\":\"close_spy\",\"Volume\":\"vol_spy\"})\n",
    "             .reset_index(drop=True))\n",
    "    return (spydf,tsladf)\n",
    "```\n",
    "- add link for:\n",
    "    - analysis/scripts\n",
    "    - FunctionWithMC.ipynb\n",
    "---\n",
    "## **3. Process Data**\n",
    "### Steps taken:\n",
    "- I created another function with method-chaining called \"remove_dates\" that allows me to remove the dates that are out of my specified range in the SPY dataframe. This function is to be run after \"load_and_clean_tsla_spy\".\n",
    "---\n",
    "```\n",
    "x=load_and_clean_tsla_spy(spy,tsla)\n",
    "spydf=x[0]\n",
    "\n",
    "removeolder=pd.to_datetime(\"2010-06-28\")\n",
    "removenewer=pd.to_datetime(\"2020-02-04\")\n",
    "def remove_dates(spydf):\n",
    "    spyclean = (pd.DataFrame(spydf)\n",
    "               .loc[(spydf.Date > removeolder)]\n",
    "                .loc[(spydf.Date < removenewer)]\n",
    "                .reset_index(drop=True))\n",
    "    return spyclean\n",
    "```\n",
    "- add link for:\n",
    "    - analysis/scripts\n",
    "    - FunctionWithMC.ipynb\n",
    "---\n",
    "## **4. Wrangle Data**\n",
    "### Steps taken:\n",
    "- I created a third function with method-chaining called \"merge_n_round\" that takes cleaned/processed dataframes, merges them together, and rounds the numbers to 2 decimal places for ease of reading.\n",
    "- I also added 2 columns: daygain_tsla and daygain_spy \n",
    "---\n",
    "```\n",
    "y=remove_dates(spydf)\n",
    "spydf=y\n",
    "tsladf=x[1]\n",
    "tslaspymerged=(spydf,tsladf)\n",
    "\n",
    "def merge_n_round(tslaspymerged):\n",
    "    \n",
    "    tslaspymerged = (pd.DataFrame(pd.merge(spydf,tsladf, how = 'inner'))\n",
    "                     .round(decimals=2))\n",
    "    return tslaspymerged\n",
    "```\n",
    "- add link for: \n",
    "    - analysis/scripts\n",
    "    - FunctionWithMC.ipynb\n",
    "---\n",
    "## **5. Exploratory Data analysis**\n",
    "### Steps taken:\n",
    "- For this task, I imported my 3 project functions and then used the cleaned dataframe to conduct exploratory data analysis\n",
    "---\n",
    "### Plot 1:\n",
    "- I created a plot out of the dataframe that shows the daily volume of SPY & TSLA from 2010-2020.\n",
    "---\n",
    "\n",
    "```\n",
    "\n",
    "edadf=finalmergeddf[['Date','vol_tsla','vol_spy']]\n",
    "df = pd.DataFrame(data=edadf)\n",
    "\n",
    "ax = df.plot(x=\"Date\", y=\"vol_tsla\", legend=True, color=\"green\", figsize=(18,10))\n",
    "\n",
    "ax2 = ax.twinx()\n",
    "df.plot(x=\"Date\", y=\"vol_spy\", ax=ax2, legend=True, color=\"r\",figsize=(18,10))\n",
    "ax.figure.legend()\n",
    "plt.show()\n",
    "\n",
    "```\n",
    "---\n",
    "- I was interested in seeing how much of a change there was in volume from 2010-2020 for both.\n",
    "- I then used the data to print out the mean volume for the first 365 days and last 365 days of the dataframe.\n",
    "---\n",
    "```\n",
    "tslavolfirst365=\"TSLA's mean volume for the first 365 days traded on the dataset is:\",np.mean(df.vol_tsla.head(365))\n",
    "tslavollast365=\"TSLA's mean volume for the last 365 days traded on the dataset is:\",np.mean(df.vol_tsla.tail(365))\n",
    "spyvolfirst365=\"SPY's mean volume for the first 365 days traded on the dataset is:\",np.mean(df.vol_spy.head(365))\n",
    "spyvollast365=\"SPY's mean volume for the last 365 days traded on the dataset is:\",np.mean(df.vol_spy.tail(365))\n",
    "\n",
    "print(tslavolfirst365)\n",
    "print(tslavollast365)\n",
    "print(spyvolfirst365)\n",
    "print(spyvollast365)\n",
    "```\n",
    "---\n",
    "- The output is as follows:\n",
    "\n",
    "```\n",
    "\n",
    "(\"TSLA's mean volume for the first 365 days traded on the dataset is:\", 1406631.7808219178)\n",
    "(\"TSLA's mean volume for the last 365 days traded on the dataset is:\", 9843472.87671233)\n",
    "(\"SPY's mean volume for the first 365 days traded on the dataset is:\", 209259411.50684932)\n",
    "(\"SPY's mean volume for the last 365 days traded on the dataset is:\", 79445112.05479452)\n",
    "\n",
    "```\n",
    "---\n",
    "### Plot 2:\n",
    "- I created another plot because out of personal interest, I simply wanted to see the TSLA/SPY close price together on one chart.\n",
    "---\n",
    "\n",
    "\n",
    "```\n",
    "\n",
    "dfx=finalmergeddf\n",
    "\n",
    "df = pd.DataFrame(data=dfx)\n",
    "\n",
    "ax = df.plot(x=\"Date\", y=\"close_tsla\",color=\"green\", figsize=(8,8))\n",
    "\n",
    "ax2 = ax.twiny()\n",
    "df.plot(x='Date', y=\"close_spy\", ax=ax2, color=\"r\",figsize=(8,8))\n",
    "plt.title('Closing prices of tsla and spy from 2010-2020')\n",
    "plt.show()\n",
    "\n",
    "```\n",
    "---\n",
    "### Plot 3:\n",
    "- I created a plot called daily gain that shows the daily gain/loss for SPY/TSLA (using closeprice-openprice).\n",
    "- I wanted to see how much more volatile the TSLA daygain was vs. SPY's daygain.\n",
    "---\n",
    "```\n",
    "\n",
    "dfx['daygain_tsla']=dfx['close_tsla']-dfx['open_tsla']\n",
    "dfx['daygain_spy']=dfx['close_spy']-dfx['open_spy']\n",
    "df = pd.DataFrame(data=dfx)\n",
    "\n",
    "ax = df.plot(x=\"Date\", y=\"daygain_tsla\",color=\"orange\", figsize=(8,8),kind='line')\n",
    "\n",
    "ax2 = ax.twiny()\n",
    "df.plot(x='Date', y=\"daygain_spy\", ax=ax2, color=\"blue\",figsize=(8,8),kind='line')\n",
    "plt.title('Daily gain (close-open) for TSLA & SPY')\n",
    "plt.ylabel('daily gain/loss in USD')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "```\n",
    "---\n",
    "\n",
    " \n",
    "\n",
    "\n",
    "- add links of:\n",
    "    -EDA(Task3).ipynb\n",
    "        -Plot 1\n",
    "        -Plot 2\n",
    "        -Plot 3\n",
    "---\n",
    "## **6. Data Analysis**\n",
    "### Steps taken:\n",
    "- For this task, I used my imported project functions to clean the dataframes and merge them. I then created a few visualizations to help answer my research questions in relation to volume and daygain of TSLA and SPY.\n",
    "- I also added a bunch more plots after receiving feedback from milestone 2.\n",
    "- Consists of 7 figures and various volume/gain/analyses\n",
    "- The variables that I plan on analyzing include: Date, Open, Close, and Volume. \n",
    "- Potential questions I plan on answering are: \"Does volume effect/correlate with the close price for tsla or spy?\" \n",
    "- \"Analysis of volume increase/decrease SPY/TSLA\"\n",
    "- I am also going to analyze daygain/volume/date/close price and if there are any correlations between the variables. \n",
    "\n",
    "#### FIGURE 1 Daygain and volume: \n",
    "- plot 1: All days of data set (2010-2020)\n",
    "- plot 2: 1st 365 days of data set (2010-2011)\n",
    "- plot 3: last 365 days of data set (2019-2020)\n",
    "#### FIGURE 2 Volume by date for TSLA and SPY:\n",
    "- plot 1: Volume by date for TSLA, from entire dataset (2010-2020)\n",
    "- plot 2: Volume by date for SPY, from entire dataset (2010-2020)\n",
    "- plot 3: Volume by date for TSLA, first 365 days from dataset (~2010-2011)\n",
    "- plot 4: Volume by date for SPY, first 365 days from dataset (~2010-2011)\n",
    "- plot 5: Volume by date for TSLA, last 365 days from dataset (~2019-2020)\n",
    "- plot 6: Volume by date for SPY, last 365 days from dataset (~2019-2020)\n",
    "#### FIGURE 3 More volume analysis between TSLA and SPY (2 y axis):\n",
    "- plot 1: TSLA vs. SPY vol analysis, entire data set\n",
    "- plot 2: TSLA vs. SPY vol analysis, first 365 days of dataset.\n",
    "- plot 3: TSLA vs. Spy vol analysis, last 365 days of dataset.\n",
    "#### FIGURE 4 TSLA/SPY Volume and Close price by Date:\n",
    "- plot 1: TSLA/SPY Volume and Close price by Date from entire dataset\n",
    "- plot 2: TSLA/SPY Volume and Close price by Date from first 365 days of dataset\n",
    "- plot 3: TSLA/SPY Volume and Close price by Date from last 365 days of dataset\n",
    "#### FIGURE 5 Daygain for TSLA/SPY by date.\n",
    "- plot 1: Daygain for TSLA/SPY by date - entire dataset.\n",
    "- plot 2: Daygain for TSLA/SPY by date - 1st 365 days.\n",
    "- plot 3: Daygain for TSLA/SPY by date - last 365 days.\n",
    "#### FIGURE 6 More volume analysis between TSLA and SPY (1 Y-Axis).\n",
    "- plot 1: TSLA vs. SPY vol analysis, entire data set\n",
    "- plot 2: TSLA vs. SPY vol analysis, first 365 days of dataset.\n",
    "- plot 3: TSLA vs. Spy vol analysis, last 365 days of dataset.\n",
    "#### FIGURE 7 Close price TSLA/SPY by Date:\n",
    "- plot 1: Close price TSLA/SPY by Date - entire dataset\n",
    "- plot 2: Close price TSLA/SPY by Date - 1st 365 days\n",
    "- plot 3: Close price TSLA/SPY by Date - last 365 days\n",
    "\n",
    "- add links: TASK4.ipynb \n",
    "---\n",
    "## **7. Export reports/data analyses and visualizations (not required for this Task)**\n",
    "### Steps taken:\n",
    "---\n",
    "## **8. Address feedback from T.A**\n",
    "---\n",
    "### Feedback from T.A:\n",
    "- What I did in regards to the feedback will be shown after below after '------'\n",
    "\n",
    "```\n",
    "In General\n",
    "[1] It is highly recommended that you justify your project. Please note that the Jupyter notebook supports markdown, and you can use this feature to  make your project clearer.\n",
    "------ Updated analysis pipeline and various readme.md's to act more as a guide and make my project more clear. Also justified the questions in the main readme.md  \n",
    "Task 1\n",
    "[1] good work\n",
    "------ Added explanation of Task 1&2 to pipeline.\n",
    "Task 2\n",
    "[1] Nice work\n",
    "------ Added explanation of Task 1&2 to pipeline.\n",
    "Task 3\n",
    "[1 ] You need to use comments to justify your work.\n",
    "------ I added my reasoning for why I chose to use these charts in Step 5 of the AnalysisPipeline.\n",
    "[2] While you have created very good charts, it is hard to understand why you have generated them.\n",
    "------ I added my reasoning for why I chose to use these charts in Step 5 of the AnalysisPipeline.\n",
    "Task 4\n",
    "[1] You need more charts to support your research question.\n",
    "------ added way more charts\n",
    "[2] The charts that you have used seems not proper for your research question\n",
    "------ tweaked research question a little bit and added different charts.\n",
    "[3] Appart from chart you need some reports, which need to be created using python\n",
    "------ WIP\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dafc1ed2-1074-4f9f-a097-fe39e954d7df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "bdc89ddb-7dc9-4dc5-8ba8-62bf05541cc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-06-29</td>\n",
       "      <td>106.019997</td>\n",
       "      <td>107.510002</td>\n",
       "      <td>103.550003</td>\n",
       "      <td>104.209999</td>\n",
       "      <td>84.502396</td>\n",
       "      <td>373649500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-06-30</td>\n",
       "      <td>103.919998</td>\n",
       "      <td>104.879997</td>\n",
       "      <td>102.879997</td>\n",
       "      <td>103.220001</td>\n",
       "      <td>83.699646</td>\n",
       "      <td>284101700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-07-01</td>\n",
       "      <td>103.150002</td>\n",
       "      <td>103.489998</td>\n",
       "      <td>101.129997</td>\n",
       "      <td>102.760002</td>\n",
       "      <td>83.326614</td>\n",
       "      <td>382924800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-07-02</td>\n",
       "      <td>103.110001</td>\n",
       "      <td>103.419998</td>\n",
       "      <td>101.620003</td>\n",
       "      <td>102.199997</td>\n",
       "      <td>82.872505</td>\n",
       "      <td>233385200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-07-06</td>\n",
       "      <td>103.639999</td>\n",
       "      <td>104.370003</td>\n",
       "      <td>101.879997</td>\n",
       "      <td>102.870003</td>\n",
       "      <td>83.415825</td>\n",
       "      <td>256935300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2411</th>\n",
       "      <td>2020-01-28</td>\n",
       "      <td>325.059998</td>\n",
       "      <td>327.850006</td>\n",
       "      <td>323.600006</td>\n",
       "      <td>326.890015</td>\n",
       "      <td>320.897308</td>\n",
       "      <td>63834000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2412</th>\n",
       "      <td>2020-01-29</td>\n",
       "      <td>328.380005</td>\n",
       "      <td>328.630005</td>\n",
       "      <td>326.399994</td>\n",
       "      <td>326.619995</td>\n",
       "      <td>320.632233</td>\n",
       "      <td>53888900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2413</th>\n",
       "      <td>2020-01-30</td>\n",
       "      <td>324.359985</td>\n",
       "      <td>327.910004</td>\n",
       "      <td>323.540009</td>\n",
       "      <td>327.679993</td>\n",
       "      <td>321.672821</td>\n",
       "      <td>75491800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2414</th>\n",
       "      <td>2020-01-31</td>\n",
       "      <td>327.000000</td>\n",
       "      <td>327.170013</td>\n",
       "      <td>320.730011</td>\n",
       "      <td>321.730011</td>\n",
       "      <td>315.831909</td>\n",
       "      <td>113845600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2415</th>\n",
       "      <td>2020-02-03</td>\n",
       "      <td>323.350006</td>\n",
       "      <td>326.160004</td>\n",
       "      <td>323.220001</td>\n",
       "      <td>324.119995</td>\n",
       "      <td>318.178101</td>\n",
       "      <td>69242300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2416 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date        Open        High         Low       Close   Adj Close  \\\n",
       "0    2010-06-29  106.019997  107.510002  103.550003  104.209999   84.502396   \n",
       "1    2010-06-30  103.919998  104.879997  102.879997  103.220001   83.699646   \n",
       "2    2010-07-01  103.150002  103.489998  101.129997  102.760002   83.326614   \n",
       "3    2010-07-02  103.110001  103.419998  101.620003  102.199997   82.872505   \n",
       "4    2010-07-06  103.639999  104.370003  101.879997  102.870003   83.415825   \n",
       "...         ...         ...         ...         ...         ...         ...   \n",
       "2411 2020-01-28  325.059998  327.850006  323.600006  326.890015  320.897308   \n",
       "2412 2020-01-29  328.380005  328.630005  326.399994  326.619995  320.632233   \n",
       "2413 2020-01-30  324.359985  327.910004  323.540009  327.679993  321.672821   \n",
       "2414 2020-01-31  327.000000  327.170013  320.730011  321.730011  315.831909   \n",
       "2415 2020-02-03  323.350006  326.160004  323.220001  324.119995  318.178101   \n",
       "\n",
       "         Volume  \n",
       "0     373649500  \n",
       "1     284101700  \n",
       "2     382924800  \n",
       "3     233385200  \n",
       "4     256935300  \n",
       "...         ...  \n",
       "2411   63834000  \n",
       "2412   53888900  \n",
       "2413   75491800  \n",
       "2414  113845600  \n",
       "2415   69242300  \n",
       "\n",
       "[2416 rows x 7 columns]"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Task 1 - Step 1 & 2 here\n",
    "\n",
    "#Used: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.to_datetime.html\n",
    "#Used: https://stackoverflow.com/questions/58867452/drop-rows-from-pandas-dataframe-according-to-date\n",
    "spy = \"~/project-group23-project/data/raw/spy.csv\"\n",
    "tsla = \"~/project-group23-project/data/raw/TSLA.csv\"\n",
    "\n",
    "spydf=pd.read_csv(spy)\n",
    "tsladf=pd.read_csv(tsla)\n",
    "\n",
    "#print(tsladf.describe().T)\n",
    "#print(spydf.describe().T)\n",
    "#print(len(spydf))\n",
    "#print(len(tsladf))\n",
    "#spydf.to_datetime\n",
    "#spydf.dtypes\n",
    "\n",
    "spydf['Date']=pd.to_datetime(spydf[\"Date\"])\n",
    "\n",
    "\n",
    "spydf = spydf[spydf.Date>pd.to_datetime('2010-06-28')]\n",
    "spydf = spydf[spydf.Date<pd.to_datetime('2020-02-04')]\n",
    "spydf = spydf.reset_index()\n",
    "spydf = spydf.drop(columns = 'index')\n",
    "spydf\n",
    "\n",
    "# Here I converted spydf's 'Date' column into a datetime object\n",
    "# I then made the range of dates from spydf match the tsladf.\n",
    "# 2010-06-29 is the first date on BOTH dataframes\n",
    "# 2020-02-03 is the last date on BOTH dataframes\n",
    "# Both dataframes are now 2416 rows x 7 columns\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "1b1c1066-a8d8-4536-81f9-6ed8ab87daeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 1 - Step 3 HERE:\n",
    "# I plan on removing the \"High\", \"Low\", \"Adj Close\" columns from both dataframes as of right now\n",
    "#spydf = spydf.drop(columns=[\"High\",\"Low\",\"Adj Close\"])\n",
    "#tsladf = tsladf.drop(columns=[\"High\",\"Low\",\"Adj Close\"])\n",
    "# They are now both 2416 rows x 4 columns. \n",
    "# I am going to also convert TSLA to datetime\n",
    "#tsladf['Date']=pd.to_datetime(tsladf[\"Date\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "63e71583-7649-4ed1-9d03-7e47024f922a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>open_tsla</th>\n",
       "      <th>close_tsla</th>\n",
       "      <th>vol_tsla</th>\n",
       "      <th>open_spy</th>\n",
       "      <th>close_spy</th>\n",
       "      <th>vol_spy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-06-29</td>\n",
       "      <td>19.00</td>\n",
       "      <td>23.89</td>\n",
       "      <td>18766300</td>\n",
       "      <td>106.02</td>\n",
       "      <td>104.21</td>\n",
       "      <td>373649500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-06-30</td>\n",
       "      <td>25.79</td>\n",
       "      <td>23.83</td>\n",
       "      <td>17187100</td>\n",
       "      <td>103.92</td>\n",
       "      <td>103.22</td>\n",
       "      <td>284101700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-07-01</td>\n",
       "      <td>25.00</td>\n",
       "      <td>21.96</td>\n",
       "      <td>8218800</td>\n",
       "      <td>103.15</td>\n",
       "      <td>102.76</td>\n",
       "      <td>382924800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-07-02</td>\n",
       "      <td>23.00</td>\n",
       "      <td>19.20</td>\n",
       "      <td>5139800</td>\n",
       "      <td>103.11</td>\n",
       "      <td>102.20</td>\n",
       "      <td>233385200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-07-06</td>\n",
       "      <td>20.00</td>\n",
       "      <td>16.11</td>\n",
       "      <td>6866900</td>\n",
       "      <td>103.64</td>\n",
       "      <td>102.87</td>\n",
       "      <td>256935300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2411</th>\n",
       "      <td>2020-01-28</td>\n",
       "      <td>568.49</td>\n",
       "      <td>566.90</td>\n",
       "      <td>11788500</td>\n",
       "      <td>325.06</td>\n",
       "      <td>326.89</td>\n",
       "      <td>63834000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2412</th>\n",
       "      <td>2020-01-29</td>\n",
       "      <td>575.69</td>\n",
       "      <td>580.99</td>\n",
       "      <td>17801500</td>\n",
       "      <td>328.38</td>\n",
       "      <td>326.62</td>\n",
       "      <td>53888900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2413</th>\n",
       "      <td>2020-01-30</td>\n",
       "      <td>632.42</td>\n",
       "      <td>640.81</td>\n",
       "      <td>29005700</td>\n",
       "      <td>324.36</td>\n",
       "      <td>327.68</td>\n",
       "      <td>75491800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2414</th>\n",
       "      <td>2020-01-31</td>\n",
       "      <td>640.00</td>\n",
       "      <td>650.57</td>\n",
       "      <td>15719300</td>\n",
       "      <td>327.00</td>\n",
       "      <td>321.73</td>\n",
       "      <td>113845600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2415</th>\n",
       "      <td>2020-02-03</td>\n",
       "      <td>673.69</td>\n",
       "      <td>780.00</td>\n",
       "      <td>47065000</td>\n",
       "      <td>323.35</td>\n",
       "      <td>324.12</td>\n",
       "      <td>69242300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2416 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date  open_tsla  close_tsla  vol_tsla  open_spy  close_spy  \\\n",
       "0    2010-06-29      19.00       23.89  18766300    106.02     104.21   \n",
       "1    2010-06-30      25.79       23.83  17187100    103.92     103.22   \n",
       "2    2010-07-01      25.00       21.96   8218800    103.15     102.76   \n",
       "3    2010-07-02      23.00       19.20   5139800    103.11     102.20   \n",
       "4    2010-07-06      20.00       16.11   6866900    103.64     102.87   \n",
       "...         ...        ...         ...       ...       ...        ...   \n",
       "2411 2020-01-28     568.49      566.90  11788500    325.06     326.89   \n",
       "2412 2020-01-29     575.69      580.99  17801500    328.38     326.62   \n",
       "2413 2020-01-30     632.42      640.81  29005700    324.36     327.68   \n",
       "2414 2020-01-31     640.00      650.57  15719300    327.00     321.73   \n",
       "2415 2020-02-03     673.69      780.00  47065000    323.35     324.12   \n",
       "\n",
       "        vol_spy  \n",
       "0     373649500  \n",
       "1     284101700  \n",
       "2     382924800  \n",
       "3     233385200  \n",
       "4     256935300  \n",
       "...         ...  \n",
       "2411   63834000  \n",
       "2412   53888900  \n",
       "2413   75491800  \n",
       "2414  113845600  \n",
       "2415   69242300  \n",
       "\n",
       "[2416 rows x 7 columns]"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Task 1 - Step 4 here\n",
    "# I plan on merging the two dataframes into one.\n",
    "# However, after a few attempts, I realized the column names are equivalent on both dataframes, so I will have to rename the columns.\n",
    "\n",
    "# USED: https://stackoverflow.com/questions/11346283/renaming-column-names-in-pandas\n",
    "# USED: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.rename.html\n",
    "# USED: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.merge.html\n",
    "# USED: https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.round.html\n",
    "#spydf=spydf.rename(columns = {\"Open\":\"open_spy\",\"Close\":\"close_spy\",\"Volume\":\"vol_spy\"})\n",
    "#tsladf=tsladf.rename(columns = {\"Open\":\"open_tsla\", \"Close\":\"close_tsla\",\"Volume\":\"vol_tsla\"})\n",
    "# I renamed a few columns to prepare for merging to a new dataframe.\n",
    "\n",
    "tslaspydf = pd.DataFrame(pd.merge(tsladf,spydf,how='inner'))\n",
    "tslaspydf = tslaspydf.round(decimals = 2)\n",
    "tslaspydf\n",
    "# the two dataframes are now merged into a dataframe called \"tslaspydf\"\n",
    "# I also rounded the decimals to 2 places because it looks a lot nicer than 8.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c6b832-486a-424c-aa30-cbd526c0fc29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e330e7-2617-4a4f-88a7-d3a8fcf9adc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93339bea-d7e4-40dd-af73-a96d0281bdef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
